# -*- coding: utf-8 -*-
"""ManyCore_HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xW3Oiaoz_qWcn1wRlVCbkUdHLVhEP4WW
"""

import random
import numpy as np
from copy import deepcopy
from dataclasses import dataclass
import pandas as pd
import math
import networkx as nx
import time
from sklearn.ensemble import RandomForestRegressor
import collections

def mesh_generate():
    
    #Generating the mesh configuration
    
    core_connect=[]
    for k in range(63):
        
        if k in [56,57,58,59,60,61,62,63]:  
            core_connect.append([k,k+1])
       
        elif k in [7,15,23,31,39,47,55]:    
            core_connect.append([k,k+8])
        
        else:
            core_connect.append([k,k+1])
            core_connect.append([k,k+8])
    return core_connect

def adj_matrix(coreConnections):
    
    
    shape=(64,64) 
    # arranging the core in 8x8 grid 
    matrix_mesh=np.zeros(shape)
    # Value of the matrix is 1 where connections are present otherwise 0.
    for connect in coreConnections:
            matrix_mesh[connect[1]][connect[0]]=1
            matrix_mesh[connect[0]][connect[1]]=1
           
    return matrix_mesh

def core_link(adjMatrix,core1,core2): 
    
       
    network_Adj=nx.from_numpy_matrix(adjMatrix,create_using=nx.DiGraph())
    # For calculating the shortest path between two cores.
    dijkstra_length=nx.shortest_path_length(network_Adj,core1,core2)
    if dijkstra_length > 4:
        return 0
    else:
        return 1

def link_swap(core1,core2,Scurrent,Tcurrent):
    
     
    
    Scurrent_copy=deepcopy(Scurrent)   
    core_connected=[]
    core_count=-1
    num_links=np.sum(Scurrent_copy[core2])  
    if num_links < 7:
        for k in Scurrent_copy[core1]:
            core_count+=1
            if k==1:
                core_connected.append(core_count)
         
        coreLink_destroy=random.choice(core_connected)
        
        if (np.sum(Scurrent_copy[coreLink_destroy])==1):  
            perturbation(Scurrent,Tcurrent)
        else:
           
            Scurrent_copy[core1][coreLink_destroy]=0
            Scurrent_copy[coreLink_destroy][core1]=0
            Scurrent_copy[core1][core2]=1
            Scurrent_copy[core2][core1]=1                
    else:
        perturbation(Scurrent,Tcurrent)
    return Scurrent_copy

def swap_tile(core1,core2,Tcurrent):
    
       
    Tcurrent_copy=deepcopy(Tcurrent)
    Tcurrent_copy[core1], Tcurrent_copy[core2] = Tcurrent_copy[core2], Tcurrent_copy[core1]
    return Tcurrent_copy

def perturbation(Scurrent,Tcurrent):
    
      
    
    link_tile = random.randint(0,1)
    valid_core=0
   # allocating tasks to the cores using random function.
    core_1=random.randint(0,63)
    core_2=random.randint(0,63)
    
    S_new = deepcopy(Scurrent)
    T_new = deepcopy(Tcurrent)
    
    if (Scurrent[core_1][core_2]==1 or core_1==core_2):
        perturbation(Scurrent,Tcurrent)
    else:
        if link_tile==0:
            
            valid_core=core_link(Scurrent,core_1,core_2)
            if valid_core == 1:
                S_new=link_swap(core_1,core_2,Scurrent,Tcurrent)
            elif valid_core == 0:
                perturbation(Scurrent,Tcurrent)
        elif link_tile==1:
            
            T_new=swap_tile(core_1,core_2,Tcurrent)
    return S_new,T_new

def calculate_distance(num_nodes,grid):
    
       
    distance_Matrix = np.zeros((num_nodes,num_nodes))
    for row in range(num_nodes):
        val =row / grid
        x_coordinate = (int)(val)
        y_coordinate = row % grid
        for column in range(num_nodes):
            val=column / grid
            xn_coordinate = (int)(val)
            yn_coordinate = column % grid
            x_distance = (xn_coordinate-x_coordinate)**2
            y_distance = (yn_coordinate-y_coordinate)**2
            # For calculating the distance between the two cores.
            distance_Matrix[row][column] = (x_distance + y_distance)**0.5
    return distance_Matrix

def hop_count(adj_matrix,num_nodes):
    
     
    hop_Count=np.zeros((num_nodes,num_nodes)) 
    network_Adj=nx.from_numpy_matrix(adj_matrix,create_using=nx.DiGraph())
    for j in range(num_nodes):
        for k in range(num_nodes):
             # calculating the hop count for the shortest path.
            hop_Count[j][k]=nx.shortest_path_length(network_Adj,j,k)  
    return hop_Count

def link_length(adj_matrix,distance,num_nodes):
       
    LinkLength=np.zeros((num_nodes,num_nodes))
    
    length_matrix=np.multiply(adj_matrix,distance)    
    network_length=nx.from_numpy_matrix(length_matrix,create_using=nx.DiGraph())
    path_dijkstra=[]
    for i in range(num_nodes):
        for j in range(num_nodes):
            if i==j:
                LinkLength[i][j]=0
            else:
                
                path_dijkstra=nx.dijkstra_path(network_length,i,j)
                source_destination=[]
                path_length=[]
                for x in range(len(path_dijkstra)-1):
                    source_destination.append([path_dijkstra[x],path_dijkstra[x+1]])
                
                for cores in source_destination:
                    path_length.append(length_matrix[cores[0]][cores[1]])
                
                LinkLength[i][j]=np.sum(path_length)
    return LinkLength

def Cost(adj_matrix,task_matrix,distance,traffic_data,num_nodes):
    
  
    
    hopCount_Matrix=np.zeros((num_nodes,num_nodes))
    linkLength_Matrix=np.zeros((num_nodes,num_nodes))
    cost_Vector=[]
    cost=0
    cost_Final=0
    
    hopCount_Matrix=hop_count(adj_matrix,num_nodes)
    
    linkLength_Matrix=link_length(adj_matrix,distance,num_nodes) 
    
    for i in range(num_nodes):
        for j in range(num_nodes):
            task=task_matrix[j]
            
            cost=((3*hopCount_Matrix[i][j] + math.ceil(linkLength_Matrix[i][j])) * traffic_data[task][i])
            cost_Vector.append(cost)
    cost_Final=np.sum(cost_Vector)
    return cost_Final

def decay_probability(Cnew,C,T):
    
   #calulating the decay.    
    del_T = Cnew - C
    decay_prob = math.exp(-del_T/T)
    return decay_prob

def stage(calculate_distance,traffic_data,num_iter,count_Repeat,memory_X,memory_Y,Scurrent,Tcurrent,Ccurrent):
    # IMPLEMENTING STAGE ALGORITHM
    
    num_nodes=64
    grid=8
    
    cost_queue=collections.deque(maxlen=count_Repeat)
    predict_queue=collections.deque(maxlen=count_Repeat)
    
    cost_queue.clear()
    predict_queue.clear()
    training_data=[]
    for i in range(num_iter):
        # Get new configuration using the perturb function.
        Sneigh,Tneigh = perturbation(Scurrent,Tcurrent)
        
        Cneigh=Cost(Sneigh,Tneigh,calculate_distance,traffic_data,num_nodes)
        
        if Cneigh < Ccurrent:
            Scurrent=Sneigh
            Tcurrent=Tneigh
            Ccurrent=Cneigh
        current_feature=[]
        features=[]
        
        up_tril=Scurrent[np.triu_indices(num_nodes, k = 1)]
        input_features=[up_tril,Tcurrent]
        
        features=[x for y in input_features for x in y]
        for i in features:
            current_feature.append(i)
        
        memory_X.append(current_feature)
        training_data.append(current_feature)        
        cost_queue.append(Ccurrent)
        
        if len(cost_queue)==count_Repeat:
            cost_val=cost_queue[0]
            min_costVal=cost_val-100
            max_costVal=cost_val+100
            count=0
            for i in range(len(cost_queue)):
                if (min_costVal < cost_queue[i]) and (max_costVal > cost_queue[i]):
                    count=count+1
            if count==count_Repeat:
                Ccurrent = cost_queue[count_Repeat-1]
                break
    # Training the regressor with the training data
    x_Train=np.array(memory_X)
    len_training=len(training_data)
    # 
    labels = [Ccurrent]*len_training
    for i in labels:
        memory_Y.append(i)
    y_Train = memory_Y
    regressor = RandomForestRegressor(n_estimators=20, random_state=0)  
    regressor.fit(x_Train, y_Train)  
    Pcurrent=Ccurrent
    for i in range(num_iter):
        training_Sneigh=[]
        current_feature1=[]
        features1=[]   
       
        Sneigh,Tneigh = perturbation(Scurrent,Tcurrent)
        
       
        up_tril1=Sneigh[np.triu_indices(num_nodes, k = 1)]
        input_features1=[up_tril1,Tneigh]
        features1=[x for y in input_features1 for x in y]
        for i in features1:
            current_feature1.append(i)
        training_Sneigh.append(current_feature1)
        Pneigh = regressor.predict(training_Sneigh)   
       
        if Pneigh < Pcurrent:
            Scurrent=Sneigh
            Tcurrent=Tneigh
            Pcurrent=Pneigh
        predict_queue.append(Pcurrent)
       
        if len(predict_queue)==count_Repeat:
            predict_val=predict_queue[0]
            min_predictVal=predict_val-100
            max_predictVal=predict_val+100
            count_P=0
            for i in range(len(predict_queue)):
                if (min_predictVal < predict_queue[i]) and (max_predictVal > predict_queue[i]):
                    count_P=count_P+1
            if count_P==count_Repeat:
                Pcurrent = predict_queue[count_Repeat-1]
                break
    return Scurrent,Tcurrent,Ccurrent,memory_X,memory_Y

def callStage(traffic_data,num_iter,count_Repeat):
    
   
    
    start=time.time()
   
    memory_X=[]
    memory_Y=[]
    cost_queue1=collections.deque(maxlen=count_Repeat)
    cost_queue1.clear()
    
    num_nodes=64
    grid=8
    # Calculating the distance matrix
    Distance=calculate_distance(num_nodes,grid) 
    distance=np.array(Distance)  
    # Base Condition for the mesh configuration
    core_Connections=mesh_generate()
    Scurrent=adj_matrix(core_Connections)
    Tcurrent=[i for i in range(64)]
    Ccurrent=Cost(Scurrent,Tcurrent,distance,traffic_data,num_nodes)
    print("Cost function for Mesh",Ccurrent)
    
    for i in range(num_iter):
        
        Scurrent,Tcurrent,Ccurrent,memory_X,memory_Y=stage(distance,traffic_data,num_iter,count_Repeat,memory_X,memory_Y,Scurrent,Tcurrent,Ccurrent)
        
        print("Cost Value after Stage",Ccurrent)
        cost_queue1.append(Ccurrent)
        if len(cost_queue1)==count_Repeat:
            cost_val=cost_queue1[0]
            min_costVal=cost_val-100
            max_costVal=cost_val+100
            count=0
            for i in range(len(cost_queue1)):
                if (min_costVal < cost_queue1[i]) and (max_costVal > cost_queue1[i]):
                    count=count+1
            if count==count_Repeat:
                Ccurrent = cost_queue1[count_Repeat-1]
                break   
    end=time.time()
    #calculating the total excution time.
    print("Total Execution Time:",end-start)
    return Scurrent,Tcurrent,Ccurrent

traffic_uniform = pd.read_csv("traffic_uniform.csv", delimiter=",", header=None)
traffic_complement = pd.read_csv("traffic_complement.csv", delimiter=",", header=None)
traffic_random = pd.read_csv("traffic_rand.csv", delimiter=",", header=None)

Scurrent,Tcurrent,Ccurrent=callStage(traffic_random,100,50)

adj_list = Scurrent.tolist()
for rows in adj_list:
  print(rows)

print(f'{Tcurrent}')

Scurrent,Tcurrent,Ccurrent=callStage(traffic_uniform,100,50)
adj_list = Scurrent.tolist()
for rows in adj_list:
  print(rows)

print(f'{Tcurrent}')

Scurrent,Tcurrent,Ccurrent=callStage(traffic_complement,100,50)
print(f'{Tcurrent}')
adj_list = Scurrent.tolist()
for rows in adj_list:
  print(rows)

