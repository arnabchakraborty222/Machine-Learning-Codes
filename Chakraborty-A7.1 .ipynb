{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A7.1 Autoencoder for Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have talked in lecture about how an Autoencoder nonlinearly reduces the dimensionality of data.  In this assignment you will \n",
    "1. load an autoencoder network already trained in the MNIST data,\n",
    "2. apply it to the MNIST training set to obtain the outputs of the units in the bottleneck layer as a new representation of each training set image with a greatly reduced dimensionality,\n",
    "3. Train a fully-connected classification network on this new representation.\n",
    "4. Report on the percent of training and testing images correctly classified.  Compare with the accuracy you get with the original images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [nn_torch.zip](https://www.cs.colostate.edu/~anderson/cs445/notebooks/nn_torch.zip) and extract the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import pickle\n",
    "import gzip\n",
    "import torch\n",
    "import neuralnetworks_torch as nntorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the MNIST data. You may download it here: [mnist.pkl.gz](http://deeplearning.net/data/mnist/mnist.pkl.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "Xtrain = train_set[0]\n",
    "Ttrain = train_set[1]\n",
    "\n",
    "Xtest = test_set[0]\n",
    "Ttest = test_set[1]\n",
    "\n",
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the network saved in Lecture Notes 21, run the following code.  This loads the saved torch neural network that was trained in a GPU.  It loads the state of that net (its weights) into a new net of the same structure but allocated on the CPU.\n",
    "\n",
    "First download [mnist_autoencoder.pt](https://www.cs.colostate.edu/~anderson/cs445/notebooks/mnist_autoencoder.pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = Xtrain.shape[1]\n",
    "n_hiddens_per_layer = [500, 100, 50, 50, 20, 50, 50, 100, 500]\n",
    "nnet_autoencoder = nntorch.NeuralNetwork(n_in, n_hiddens_per_layer, n_in, device='cpu')\n",
    "nnet_autoencoder.standardize = ''\n",
    "\n",
    "nnet_autoencoder.load_state_dict(torch.load('mnist_autoencoder.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the output of the units in the middle hidden layer, run `use_to_middle` function implemented for you in `neuralnetworks_torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_reduced = nnet_autoencoder.use_to_middle(Xtrain)\n",
    "Xtrain_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we are here, let's get the reduced representation of `Xtest` also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_reduced = nnet_autoencoder.use_to_middle(Xtest)\n",
    "Xtest_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "\n",
    "Your jobs are now to\n",
    "1. train one fully-connected classifier using `Xtrain_reduced` and `Ttrain` and test it with `Xtest_reduced` and `Ttest`, and\n",
    "2. train a second fully-connected classifier using `Xtrain` and `Ttrain` and test it with `Xtest` and `Ttest`.\n",
    "\n",
    "Try to find parameters (hidden network structure, number of epochs, and learning rate) for which the classifier given the reduced representation does almost as well as the other classifier with the original data. Discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example for part of Step 1.  It shows a brief training session (small number of epochs and simple hidden layer structure) for using the reduced data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: RMSE 0.412\n",
      "Epoch 20: RMSE 0.347\n",
      "Epoch 30: RMSE 0.293\n",
      "Epoch 40: RMSE 0.253\n",
      "Epoch 50: RMSE 0.219\n",
      "Epoch 60: RMSE 0.188\n",
      "Epoch 70: RMSE 0.159\n",
      "Epoch 80: RMSE 0.135\n",
      "Epoch 90: RMSE 0.115\n",
      "Epoch 100: RMSE 0.100\n",
      "% Correct  Train Reduced 97.11\n",
      "% Correct  Test Reduced 96.60\n"
     ]
    }
   ],
   "source": [
    "n_in = Xtrain_reduced.shape[1]\n",
    "reduced_classifier = nntorch.NeuralNetwork_Classifier(n_in, [200,200], 10, device='cuda')\n",
    "\n",
    "n_epochs = 100\n",
    "reduced_classifier.train(Xtrain_reduced, Ttrain, n_epochs, 0.01, method='adam', standardize='')\n",
    "\n",
    "def percent_correct(Predicted, Target):\n",
    "    return 100 * np.mean(Predicted == Target)\n",
    "\n",
    "Classes, _ = reduced_classifier.use(Xtrain_reduced)\n",
    "\n",
    "print(f'% Correct  Train Reduced {percent_correct(Classes, Ttrain):.2f}')\n",
    "\n",
    "Classes, _ = reduced_classifier.use(Xtest_reduced)\n",
    "\n",
    "print(f'% Correct  Test Reduced {percent_correct(Classes, Ttest):.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: RMSE 0.824\n",
      "Epoch 20: RMSE 0.414\n",
      "Epoch 30: RMSE 0.288\n",
      "Epoch 40: RMSE 0.227\n",
      "Epoch 50: RMSE 0.187\n",
      "Epoch 60: RMSE 0.157\n",
      "Epoch 70: RMSE 0.132\n",
      "Epoch 80: RMSE 0.113\n",
      "Epoch 90: RMSE 0.096\n",
      "Epoch 100: RMSE 0.082\n",
      "% Correct  Train Original 97.84\n",
      "% Correct  Test Original 96.01\n"
     ]
    }
   ],
   "source": [
    "n_in = Xtrain.shape[1]\n",
    "reduced_classifier = nntorch.NeuralNetwork_Classifier(n_in, [50,30], 10, device='cuda')\n",
    "\n",
    "n_epochs = 100\n",
    "reduced_classifier.train(Xtrain, Ttrain, n_epochs, 0.01, method='adam', standardize='')\n",
    "\n",
    "def percent_correct(Predicted, Target):\n",
    "    return 100 * np.mean(Predicted == Target)\n",
    "\n",
    "Classes, _ = reduced_classifier.use(Xtrain)\n",
    "\n",
    "print(f'% Correct  Train Original {percent_correct(Classes, Ttrain):.2f}')\n",
    "\n",
    "Classes, _ = reduced_classifier.use(Xtest)\n",
    "\n",
    "print(f'% Correct  Test Original {percent_correct(Classes, Ttest):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Neural Network Parameters when trained using entire dataset:\n",
    "\n",
    "Fully Connected Layer : [50,30]\n",
    "\n",
    "Learning Rate : 0.01\n",
    "\n",
    "Training Accuracy: 97.84\n",
    "\n",
    "Testing Accuracy: 96.01\n",
    "\n",
    "Number of Epochs: 100\n",
    "\n",
    "Neural Network Parameters when trained using Reduced dataset:\n",
    "\n",
    "Fully Connected Layer : [200,200]\n",
    "\n",
    "Learning Rate : 0.01\n",
    "\n",
    "Training Accuracy: 97.11\n",
    "\n",
    "Testing Accuracy: 96.60\n",
    "\n",
    "Number of Epochs: 100\n",
    "\n",
    "It was observed that when the neural network was trained using reduced datset, larger number of fully connected layer was needed to get the same accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "For 1 point of extra credit repeat this assignment using a second data set, one that we have not used in class before. This will require you to to train a new autoencoder net to use for this part."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
